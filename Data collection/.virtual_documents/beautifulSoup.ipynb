from bs4 import BeautifulSoup





# 50 pages read
soup_pages = []
for i in range(1,51):
    with open(f"htmls/page{i}.html",'r',encoding='utf-8') as f:
        cont = f.read()
        soup_ = BeautifulSoup(cont,"html.parser")
        soup_pages.append(soup_)

#extract all articals tag form (books)
artical_pages = []

for soup in soup_pages:
    articles = soup.select("article")
    artical_pages.extend(articles)

# extract title , ptice and rating
# multiple pages items
items = []
for artical in artical_pages:
    title = artical.find("h3").find("a")['title']
    price = artical.select_one("p.price_color").text.split("£")[1]
    rating_element = artical.select_one("p.star-rating")
    rating = rating_element['class'][1]
    
    # print(classes)
    items.append([title,price,rating])
# create a dataframe
df = pd.DataFrame(items,columns=["Book Title","Price","Rating"])









import pandas as pd
from bs4 import BeautifulSoup



# single file read
with open("htmls/page1.html","r") as f:
    content = f.read()

# single page
articals = soup.select("article.product_pod")

# single page
soup = BeautifulSoup(content,"html.parser")

# single page


# single page
items = []
for artical in articals:
    title = artical.find("h3").find("a")['title']
    price = artical.select_one("p.price_color").text.split("£")[1]
    rating_element = artical.select_one("p.star-rating")
    rating = rating_element['class'][1]
    
    # print(classes)
    items.append([title,price,rating])

# print the Dataframe
df = pd.DataFrame(items,columns=["Book Title","Price","Rating"])
df


df.to_csv("data.csv",index=False)

